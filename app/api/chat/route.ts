import { google } from "@ai-sdk/google";
import { streamText, UIMessage, convertToModelMessages, stepCountIs } from 'ai';
import { headers } from "next/headers";
import { auth } from "@/lib/auth";
import { prisma } from "@/lib/db";
import { generateSystemPrompt } from "@/lib/ai/prompts";
import { getToolsForRole, getToolNamesForRole } from "@/lib/ai/tool-registry";

// Allow long-running requests
export const maxDuration = 30;

export async function POST(req: Request) {
  try {
    const { messages }: { messages: UIMessage[] } = await req.json();

    // 1. Get Real Session
    const session = await auth.api.getSession({
      headers: await headers(),
    });
    
    const userId = session?.user?.id;
    const userName = session?.user?.name || undefined;
    let userRole = "USER"; // Default role
    if (session?.user?.role === "teacher") userRole = "TEACHER";
    else if (session?.user?.role === "admin") userRole = "ADMIN";

    // Pháº£i cÃ³ userId há»£p lá»‡
    if (!userId) {
      return new Response(
        JSON.stringify({ error: "Vui lÃ²ng Ä‘Äƒng nháº­p Ä‘á»ƒ sá»­ dá»¥ng Chat AI." }),
        { status: 401, headers: { "Content-Type": "application/json" } }
      );
    }

    // 2. Fetch isPremium tá»« Database (khÃ´ng dÃ¹ng session vÃ¬ cÃ³ thá»ƒ bá»‹ cache)
    let isPremium = false;
    if (userRole !== "ADMIN") {
      const user = await prisma.user.findUnique({
        where: { id: userId },
        select: { isPremium: true, premiumExpires: true }
      });
      
      const now = new Date();
      isPremium = Boolean(user?.isPremium && user?.premiumExpires && user.premiumExpires > now);
    } else {
      // Admin bypass Premium check
      isPremium = true;
    }


    // Chá»‘t cháº·n: ADMIN Ä‘Æ°á»£c bypass, cÃ²n láº¡i pháº£i lÃ  Premium
    if (userRole !== "ADMIN" && !isPremium) {
      return new Response(
        JSON.stringify({
          error: "TÃ­nh nÄƒng Chat AI chá»‰ dÃ nh cho thÃ nh viÃªn Premium.",
          code: "PREMIUM_REQUIRED"
        }),
        { status: 403, headers: { "Content-Type": "application/json" } }
      );
    }

    // 3. Validate Env
    if (!process.env.GOOGLE_GENERATIVE_AI_API_KEY) {
      return new Response(JSON.stringify({ error: "Server configuration error" }), { status: 500 });
    }

    const lastMessage = messages[messages.length - 1];
    const text = typeof lastMessage.content === 'string' ? lastMessage.content : '';

    // GUARD: Math Detection
    // Detects: 5+5, 10/2, sqrt(2), sin(30)...
    const hasMath = 
      /(^|[\s(])\d+(\.\d+)?\s*[\+\-\*\/]\s*\d+(\.\d+)?([\s)]|$)/.test(text) ||
      /(sqrt|cÄƒn|log|sin|cos|tan)\s*\(?\s*\d+/i.test(text);

    // Detects explicit course intent
    const hasCourseIntent = 
      /(khÃ³a há»c|tÃ¬m khÃ³a|gá»£i Ã½ khÃ³a|danh sÃ¡ch khÃ³a|lá»™ trÃ¬nh|nÃªn há»c|course|há»c gÃ¬|bÃ i giáº£ng)/i.test(text);

    // Náº¿u há»i toÃ¡n mÃ  KHÃ”NG cÃ³ Ã½ Ä‘á»‹nh tÃ¬m khÃ³a há»c rÃµ rÃ ng -> Cháº·n ngay
    if (hasMath && !hasCourseIntent) {
       // Return a mocked stream response that refuses math
       // Since streamText returns a stream, we need to mimic that or just return a simple text stream
       // Ideally we use a simple text response, but the client expects a stream.
       // Easiest is to just continue but force tool_choice: 'none' and let prompt handle? 
       // OR we can return a custom response.
       // The PLAN said: "If math detected... -> respond directly".
       // Let's rely on the prompt but force `toolChoice: 'none'` if we can passing it to streamText usually works.
       // However, `toolChoice` in `streamText` is static.
       // Better approach: Modify the request message or system prompt?
       // Let's try to just return a standard response if we can.
       // Actually, the simplest way to "Guard" is to just return a text response without calling Gemini if it's math.
       // But keeping it consistent with the stream is cleaner.
       // Let's use `toolChoice: 'none'` if possible. `streamText` options allows `toolChoice`.
       // We can conditionalize the config.
    }


    // 4. Dynamic Tool Selection by Role (Security + Performance)
    const tools = getToolsForRole(userRole);

    console.log(`ðŸ¤– AI Chat | User: ${userName} | Role: ${userRole} | Premium: ${isPremium} | Tools: [${getToolNamesForRole(userRole).join(', ')}]`);

    // 4. Stream using Multi-step Agent with Gemini 2.5 Flash Optimizations
    const result = streamText({
      model: google("gemini-2.5-flash"),
      system: generateSystemPrompt(userId, userRole, userName),
      messages: await convertToModelMessages(messages),
      providerOptions: {
        google: {
          thinkingBudget: 4096, // Tier 1: Cho phÃ©p AI reasoning sÃ¢u hÆ¡n
        },
      },
      
      stopWhen: stepCountIs(2), // Giá»¯ giá»›i háº¡n 2 steps
      
      // ðŸ”¥ Dynamic Tool Selection (khÃ´ng hardcode)
      // ðŸ”¥ Dynamic Tool Selection (khÃ´ng hardcode)
      tools,
      toolChoice: (hasMath && !hasCourseIntent) ? "none" : "auto",
    });

    return result.toUIMessageStreamResponse();

  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : String(error);
    console.error("ðŸ”¥ Chat Route Error:", errorMessage);
    return new Response(JSON.stringify({ error: errorMessage }), { 
      status: 500,
      headers: { "Content-Type": "application/json" }
    });
  }
}
